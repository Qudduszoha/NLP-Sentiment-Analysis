{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8b46SWUvuGx"
      },
      "source": [
        "# Using Jupyter Notebooks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk spacy gensim pandas scikit-learn\n",
        "#pip: A package-management system used to install and manage software packages written in Python.\n",
        "#install: A command used to install the specified Python libraries or modules.\n",
        "#nltk: Stands for Natural Language Toolkit, a library in Python used for working with human language data (text) and performing text processing tasks like tokenization, parsing, classification, etc.\n",
        "#spacy: A library for advanced Natural Language Processing (NLP) in Python, used for tasks like tokenization, part-of-speech tagging, named entity recognition, and more.\n",
        "#gensim: A Python library used for topic modeling and document similarity analysis, especially popular for tasks related to natural language processing and working with large text collections.\n",
        "#pandas: A Python library used for data manipulation and analysis, providing data structures like DataFrame, and functions for working with structured data.\n",
        "#scikit-learn: A Python library used for machine learning and statistical modeling, including tools for classification, regression, clustering, and dimensionality reduction."
      ],
      "metadata": {
        "id": "Osoh-IpZwuYp",
        "outputId": "f3b09eea-cb81-4309-eb59-bee77a20fb1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.2)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ3M5cCUN6i8"
      },
      "source": [
        "##Introduction\n",
        "Jupyter notebooks is an open-source web-based Python editor which runs in your browser. It allows a combination of text written in a html-like format known as \"markdown\", such as the block of text you're reading right now, and inline code, tools and outputs such as this one:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk #import: A Python keyword used to bring in external modules or libraries into your script so you can use their functions and classes.\n",
        "nltk.download('punkt') # punkt: A pre-trained tokenizer that is part of the NLTK library, used for splitting a text into sentences or words (tokenization). It is specifically designed to handle punctuation.\n",
        "from nltk.tokenize import word_tokenize # nltk.tokenize: A sub-module in the NLTK library used for breaking down text into smaller parts (tokens) like words or sentences.\n",
        "                                        # word_tokenize: A function from the nltk.tokenize module that splits a sentence into individual words (tokens).\n",
        "sentence = \"Hello, world! This is NLP.\"\n",
        "tokens = word_tokenize(sentence) # this will tokenize the given sentence in to tokens\n",
        "print(tokens) # Output: ['Hello', ',', 'world', '!', 'This', 'is','NLP', '.'] #print: A built-in Python function that outputs the specified value to the console."
      ],
      "metadata": {
        "id": "BqtrcvM2xL5h",
        "outputId": "3aa9ee3a-c602-4543-d5dc-c291f79ac0fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '!', 'This', 'is', 'NLP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GDTYoruGxMEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mks2EtD4xMMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt') # Download the Punkt tokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "#In summary, the snippet prepares for text tokenization by downloading a tokenizer and importing the function required to split sentences into words."
      ],
      "metadata": {
        "id": "AmQQ5MkGxMQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords #nltk.corpus: A sub-module in the NLTK library that provides access to a variety of linguistic resources, such as corpora, lexical resources, and word lists.\n",
        "                                  #stopwords: A collection of common words (like \"the\", \"is\", \"in\", etc.) that are often removed from text during preprocessing, as they don't carry significant meaning in natural language processing tasks.\n",
        "nltk.download('stopwords') #nltk.download('stopwords'): This downloads the NLTK stopwords corpus, a pre-compiled list of commonly used stopwords in different languages.\n",
        "stop_words = set(stopwords.words('english')) #set: A Python data structure that stores unique elements. In this case, it's used to hold the stop words, ensuring that only unique stop words are stored.\n",
        "                                             #stopwords.words('english'): A method that retrieves the list of English stopwords from the NLTK corpus.\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words] #filtered_tokens: A variable that stores the result of filtering the tokens, removing words that are present in the stop words list.\n",
        "                                                                              #word.lower(): Converts the word to lowercase to ensure case-insensitive matching when filtering out stopwords.\n",
        "\n",
        "                                                           #not in stop_words: This condition checks whether each word in the list is not present in the stop words set.\n",
        "print(filtered_tokens)\n"
      ],
      "metadata": {
        "id": "AYwn_9rSxMTx",
        "outputId": "5f00ab3b-a6ec-4e77-8681-9dd84c866bfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '!', 'NLP', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer #nltk.stem: A sub-module of the NLTK library that provides methods for stemming and lemmatization, which are text normalization techniques.\n",
        "from nltk.stem import WordNetLemmatizer # WordNetLemmatizer: A lemmatizer from the nltk.stem module that reduces words to their base or dictionary form, called the lemma, while considering the context. It uses the WordNet lexical database to ensure accurate lemmatization.\n",
        "nltk.download('wordnet') # WordNet is a large lexical database of English words grouped into sets of synonyms (synsets).\n",
        "ps = PorterStemmer() # PorterStemmer: A stemming algorithm available in the nltk.stem module. Stemming reduces words to their root form (stem), even if the result is not a valid word (e.g., \"faster\" to \"fast\").\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(ps.stem(\"faster\")) # ps.stem(\"faster\"): This method applies stemming to the word \"faster\" and reduces it to its stem form, in this case, \"fast.\"\n",
        "print(lemmatizer.lemmatize(\"faster\")) #lemmatizer.lemmatize(\"faster\"): This method applies lemmatization to the word \"faster,\" considering it as a dictionary form. Depending on the context, lemmatization requires more information to produce the correct lemma (e.g., it might return \"fast\" in some contexts).\n"
      ],
      "metadata": {
        "id": "z-jisxs7xMWw",
        "outputId": "25832466-57cd-46fc-dd47-19203ff1ce20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faster\n",
            "faster\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #Pandas is used for data manipulation and analysis, particularly with tabular data like DataFrames.\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split # sklearn.model_selection: A sub-module in scikit-learn that contains utilities for splitting datasets into training and testing sets, cross-validation, and more.\n",
        "                                                     # train_test_split: A function in sklearn.model_selection that splits data into training and testing sets for model training and evaluation.\n",
        "from sklearn.feature_extraction.text import CountVectorizer #sklearn.feature_extraction.text: A sub-module in scikit-learn that contains utilities for extracting features from text data to convert it into numeric format suitable for machine learning algorithms.\n",
        "                                                            #CountVectorizer: A function in sklearn.feature_extraction.text that converts a collection of text documents into a matrix of token counts, representing the frequency of each word (or token) in the text corpus.\n",
        "from sklearn.naive_bayes import MultinomialNB # sklearn.naive_bayes: A sub-module in scikit-learn that provides implementations of the Naive Bayes algorithm for classification tasks.\n",
        "                                              # MultinomialNB: A specific implementation of the Naive Bayes algorithm used for classification, particularly effective when features are multinomially distributed, such as word frequencies.\n",
        "from sklearn import metrics #sklearn: A popular Python library (also known as scikit-learn) that provides simple and efficient tools for data mining and data analysis, especially machine learning tasks.\n",
        "                            #metrics: A sub-module of sklearn that contains various methods to evaluate the performance of machine learning models, including accuracy, precision, recall, F1 score, etc.\n",
        "\n",
        "#In summary, this code imports essential libraries for performing machine learning tasks,particularly for text data processing, splitting the dataset, building a classification model using Naive Bayes, and evaluating the model's performance."
      ],
      "metadata": {
        "id": "V8_SafrRxMZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        " 'text': [\n",
        " 'I love this movie!',\n",
        " 'This was a terrible movie.',\n",
        " 'I really enjoyed the film.',\n",
        " 'Worst experience ever.',\n",
        " 'It was fantastic!',\n",
        " 'Not worth the time.',\n",
        " 'Absolutely amazing!',\n",
        " 'It was okay, not great.',\n",
        " 'I hate this film.',\n",
        " 'Best movie ever!'\n",
        " ],\n",
        " 'sentiment': [\n",
        " 'negative',\n",
        " 'positive',\n",
        " 'negative',\n",
        " 'positive',\n",
        " 'negative',\n",
        " 'positive',\n",
        " 'negative',\n",
        " 'neutral',\n",
        " 'negative',\n",
        " 'positive'\n",
        " ]\n",
        "}"
      ],
      "metadata": {
        "id": "9R-6RevNxMca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data) # DataFrame: A constructor in the pandas library that creates a DataFrame object, which is essentially a table with rows and columns, used for data manipulation and analysis."
      ],
      "metadata": {
        "id": "nM7-QMPaxMfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "WuzprVcA2za-",
        "outputId": "449ff830-3615-4185-f61f-ff2e3170814e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         text sentiment\n",
            "0          I love this movie!  negative\n",
            "1  This was a terrible movie.  positive\n",
            "2  I really enjoyed the film.  negative\n",
            "3      Worst experience ever.  positive\n",
            "4           It was fantastic!  negative\n",
            "5         Not worth the time.  positive\n",
            "6         Absolutely amazing!  negative\n",
            "7     It was okay, not great.   neutral\n",
            "8           I hate this film.  negative\n",
            "9            Best movie ever!  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
        "#train_test_split: A function from sklearn.model_selection that splits the data into training and testing sets. Here, X and y are split into training data (X_train, y_train) and testing data (X_test, y_test).\n",
        "#test_size=0.2: This argument specifies the proportion of the dataset to be used as the test set (20% in this case).\n",
        "#random_state=42: A parameter that sets a seed for random number generation to ensure reproducibility of the split. Using the same seed will yield the same split each time the code is run.\n",
        "\n",
        "# Vectorize the text\n",
        "vectorizer = CountVectorizer() #CountVectorizer(): This initializes a CountVectorizer object from sklearn.feature_extraction.text, which will convert the text data into a matrix of token counts (bag-of-words representation).\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train) #fit_transform(X_train): This method fits the CountVectorizer on the training data (X_train), learning the vocabulary from the text, and transforms the training text into a matrix of token counts. The result (X_train_vectorized) is a numerical representation of the text data that can be used for machine learning.\n",
        "X_test_vectorized = vectorizer.transform(X_test) # transform(X_test): This method applies the same vectorization learned from the training data to the test data (X_test). It converts the test text into a matrix of token counts using the vocabulary from the training set.\n",
        "\n",
        "#this code prepares the text data for machine learning by splitting it into training and testing sets, then vectorizing the text using the bag-of-words model (i.e., token counts). This transforms the text data into a numerical format that can be used as input for machine learning algorithms."
      ],
      "metadata": {
        "id": "xl3rcshl2zeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB() # MultinomialNB(): A function that initializes the Multinomial Naive Bayes classifier. This classifier is typically used for discrete features like word counts (i.e., the bag-of-words representation). It assumes that the features follow a multinomial distribution.\n",
        "model.fit(X_train_vectorized, y_train) #fit(): A method that trains the model on the provided training data. It adjusts the model's parameters based on the input features and the corresponding target labels. In this case, the model is trained using X_train_vectorized (the vectorized text data) and y_train (the sentiment labels)."
      ],
      "metadata": {
        "id": "3WfuP5iV2zhb",
        "outputId": "8887c679-d55a-4647-a00c-709bda4e6838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_vectorized) #model.predict(): A method used to make predictions using the trained model. It takes the input features (in this case, the vectorized test data) and outputs the predicted labels based on the learned parameters from the training phase."
      ],
      "metadata": {
        "id": "3Iei5_lB2zkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = metrics.accuracy_score(y_test, y_pred) # Accuracy is the ratio of correctly predicted instances to the total instances in the test set.\n",
        "                                                  #accuracy_score(): A function from the metrics module that computes the accuracy of the model's predictions. It takes the true labels (y_test) and the predicted labels (y_pred) as inputs.\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, y_pred) # confusion_matrix(): A function from the metrics module that computes the confusion matrix. It also takes the true labels (y_test) and the predicted labels (y_pred) as inputs.\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix)\n"
      ],
      "metadata": {
        "id": "C97Mu6N92znB",
        "outputId": "baad2791-8c2c-44ff-9a05-b8bed33e536e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00\n",
            "Confusion Matrix:\n",
            "[[0 2]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):   #def: A keyword used to define a new function in Python.\n",
        "                              #predict_sentiment: The name of the function being defined. This function is designed to predict the sentiment of a given text input.\n",
        " text_vectorized = vectorizer.transform([text]) #vectorizer.transform([text]): This method converts the input text into a numerical format (a vector of token counts) suitable for prediction. The input text is passed as a list to maintain the expected input shape.\n",
        " prediction = model.predict(text_vectorized)\n",
        " return prediction[0] #return: A statement that exits the function and sends back the specified value (in this case, the predicted sentiment) to the caller.\n",
        "                      #prediction[0]: This retrieves the first (and only) predicted sentiment label from the prediction array. The model returns an array of predictions, but since the input is a single text, we take the first element.\n",
        "# Example usage\n",
        "new_text = \"I loved the plot and the acting!\"\n",
        "print(f'Sentiment: {predict_sentiment(new_text)}')\n",
        "\n",
        "#this code defines a function to predict the sentiment of a given text input. It vectorizes the input text, makes a prediction using the trained model, and returns the predicted sentiment. An example usage is also provided to demonstrate how to call the function and print the result."
      ],
      "metadata": {
        "id": "R2BKZbFq2zpc",
        "outputId": "b8b6c1fd-88b1-4668-968a-186023165329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFG_BTei2zry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpuvM0MkxMiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHI0ogXbvuGy"
      },
      "source": [
        "print(\"Hello World\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvjJu5iNvuG1"
      },
      "source": [
        "This combination allows for the procution of beautiful documents containing software, documentation and discussion. For larger codes you may wish to use Python in a stand-alone environment such as a traditional IDE. But for demonstration purposes Jupyter is a very useful tool.\n",
        "\n",
        "Notebook files have the extension \".ipynb\" extension. A Jupyter notebook is one of many environments you may run Python code.  Colab and the Jupyter notebook editor in Anaconda are two of the many pieces of software you may use to write and run a Jupyter notebook. For this course we recommend using the online Google Colab tool, but you can use Anaconda to run the notebooks on your own machine within an internet connection. On college computers, Jupyter can be used by launchng Anaconda from the Software Hub Apps Anywhere interface.\n",
        "\n",
        "Note that exact interfaces will differ between different environments but the same functionality should be found in most environments. This course will be using the Colab environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br4ThcjVNBfb"
      },
      "source": [
        "## Cells and Executing Code\n",
        "\n",
        "A notebooks is made up of one or more \"cells\". Cells can contain the html-like text used to generate text or code to be run by the user. A cell containing a piece of code may be recognised by the the  ```[]```  to the left of it. Code in these blocks can be run in a nubmer of ways. The simplest is click on the ```[ ]``` . This will execute the code. Try this with the code snippet below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znQZKSLZvuG2"
      },
      "source": [
        "print(\"Yes, it worked!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX2A7djDvuG4"
      },
      "source": [
        "You should have seen the message \"Yes, it worked!\" appear immediately beneath the code. This is the output of the code, which has been printed to the screen. You may also have noticed a number appear between the square brackets to the left of the code snippet. This indicates the order in which the code snippet has been executed. Code cells may be executed in any order and variables will be saved between execution of code snippets. To try this, execute the three codes snippets below in the following order:\n",
        "- 1\n",
        "- 2\n",
        "- 3\n",
        "- 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAE233GJvuG4"
      },
      "source": [
        "a=\"Message 1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt9NlZYyvuG6"
      },
      "source": [
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZUIOI-ZvuG8"
      },
      "source": [
        "a=\"Message 2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCXAZCPzNUWr"
      },
      "source": [
        "The first time you ran code snippet 1 you should have seen \"Message 1\" as the output and the second time the output should have been \"Message 2\". This is because the first time it was run, the value assigned to the variable named \"a\" was \"Message\" as set by the first code snippet and the second time it was \"Message 2\" as set by the third code snippet. Note also the current numbers contained within square brackets. These help you to kno which cells have been executed and in which order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8YYhdP7NbjD"
      },
      "source": [
        "##Sharing Jupyter Notebooks on Colab\n",
        "When a Jupyter Notebook is shared with you on Colab, you will often receive access to the notebook which will alow you to run code, but not edit it. This should be the case for the notebooks that form part of this course. In this case you can select \"Save a Copy in Drive\" from the \"File\" menu to create a new copy that is yours and yo can edit.\n",
        "\n",
        "For this course, it is reccommended that you create two copies. One of these should be the original copy without your edits, and another which you can edit to compelte exercises or expierment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSpv_w2nvuG-"
      },
      "source": [
        "## Basic Jupyter Commands\n",
        "\n",
        "Jupyter contains a number of useful tools for executing these cells. By using the \"Runtime\" menu, you can run multiple cells at a time using \"Run all\", \"Run before\", \"Run selected\" and \"Run after\".\n",
        "\n",
        "You can clear output (this is the term for what is written under a code cell when it's executed) by clicking on the symbol to the left of it. You can clear all outputs from the notebook using the \"Clear All Outputs\" command on the \"Edit\" menu. Clearing the output will not unset variables set by the code snippets run, only remove the output printed to the screen.\n",
        "\n",
        "To unset variables, use the \"Restart Runtime\" or \"Reset Runtime\" option in the Runtime menu. The \"Interrupt Execution\" command on the kernel menu will halt the procesing of code, which can be useful if you've accidentally written a piece of code that will never finish executing or if the code is taking too long to execute.\n",
        "\n",
        "The \"insert\" menu allows you to create new cells. The \"cell type\" option in the \"cell\" menu allows you toggle the current cell type between the different cell types available:\n",
        "- **Code**: Code snippets\n",
        "- **Text**: The html-like language used to generate text, tables, equations, etc.\n",
        "\n",
        "Alternatively, you can hover your mouse in the space after a cell and add a code or text cell there.\n",
        "\n",
        "###Exercise\n",
        "\n",
        "Try each of these commands from the different menus for yourself on this  notebook and ensure they behave as you would expect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY8lQr8RNgnL"
      },
      "source": [
        "## Text Cells in Jupyter\n",
        "You can include all sort so information in Jupyter text cells to obtain different effects. To see how each of the following examples is generated, double click on this cell. To return to the formatted text, run the cell.\n",
        "\n",
        "### Headings\n",
        "Headings can be generated using the hash symbol \"#\". The more of these there are, the smaller the heading. The sub-sub-heading above is an example.\n",
        "\n",
        "### Tables\n",
        "Tables can be created in a way similar to basic html, using the a comabination of the \"|\" and \"-\" symbols:\n",
        "\n",
        "| This | is    |\n",
        "|------|-------|\n",
        "|   a  |  table|\n",
        "| It's | fancy |\n",
        "\n",
        "### Equations\n",
        "Equations can be written in a way similar to LaTeX by surrouding the text with \"\\$\" symbols:\n",
        "\n",
        "$a=\\frac{\\int\\limits_{0}^{\\pi} \\sin{(bx)} \\textrm{d}x}{4}$\n",
        "\n",
        "Don't worry if you don't understand the exact syntax used to generate this example. In your example of it in your exercise, try writing something very simple instead. If it looks like a simple algebraic expression, it will probably render how you intend.\n",
        "\n",
        "### Code Snippets\n",
        "You can write snippets of code in a text cell and they will be highlighted as if they were code written in a code cell. This can be useful for demonstrating a code feature in a textual way. For example:\n",
        "\n",
        "```python\n",
        "print (\"Hello World\")\n",
        "```\n",
        "\n",
        "There is not a way to run this code, it is merely normal text highlighted to look like code. The \"python\" which precedes the code itself tells Jupyter which language you are writing the code snippet in so it can be highlighted accorindly.\n",
        "\n",
        "In some environments, text cells may also be referred to as \"markdown\" cells.\n",
        "\n",
        "###Exercise\n",
        "Try creating simple versions of each of the constructs above in a new text cell below this one."
      ]
    }
  ]
}